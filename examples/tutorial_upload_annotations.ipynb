{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Uploading Annotations and Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\"><b>In this tutorial, we explore different options to upload annotations in Remo from code.</b>\n",
    "    \n",
    "<p>\n",
    "    \n",
    "In particular, we will see how to:\n",
    "\n",
    "- add annotations from a file (in a format supported by remo)\n",
    "- add annotations from code (can be used for predictions, and from any input format)\n",
    "\n",
    "    </p></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start off by creating a dataset and populating it with some images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import remo\n",
    "import os\n",
    "import pandas as pd\n",
    "remo.set_viewer('jupyter')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acquiring data - completed                                                                           \n",
      "Processing data - completed                                                                          \n",
      "Data upload completed\n"
     ]
    }
   ],
   "source": [
    "urls = ['https://remo-scripts.s3-eu-west-1.amazonaws.com/open_images_sample_dataset.zip']\n",
    "my_dataset = remo.create_dataset(name = 'D1', urls = urls)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Supported format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**To add annotations from a supported file format, we can pass the file via `dataset.add_data`**\n",
    "\n",
    "Remo automatically parses annotation files in a variety of formats (such as Pascal XML, COCO JSON, Open Images CSV, etc). You can read more about supported file formats in [our documentation](https://remo.ai/docs/annotation-formats/).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example: let's add some annotations for an Object Detection task from a CSV file with encoded classes**\n",
    "\n",
    "In this case, annotations are stored in a supported CSV file format. Class labels were encoded using [GoogleKnowledgeGraph](https://developers.google.com/knowledge-graph). Remo automatically detects the class encoding and translates it into the corresponding labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ImageID', 'Source', 'LabelName', 'Confidence', 'XMin', 'XMax', 'YMin',\n",
       "       'YMax', 'IsOccluded', 'IsTruncated', 'IsGroupOf', 'IsDepiction',\n",
       "       'IsInside'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "annotation_files=[os.getcwd() + '/assets/open_sample.csv']\n",
    "\n",
    "df = pd.read_csv(annotation_files[0])\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acquiring data - completed                                                                           \n",
      "Processing data - completed                                                                          \n",
      "Data upload completed\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'session_id': '810e23ad-ff63-42a9-89ed-400fbb7d4fc0',\n",
       " 'created_at': '2020-05-29T13:56:17.832956Z',\n",
       " 'dataset': {'id': 14, 'name': 'D1'},\n",
       " 'status': 'done',\n",
       " 'substatus': '',\n",
       " 'images': {'pending': 0,\n",
       "  'total': 0,\n",
       "  'successful': 0,\n",
       "  'failed': 0,\n",
       "  'errors': []},\n",
       " 'annotations': {'pending': 0,\n",
       "  'total': 1,\n",
       "  'successful': 1,\n",
       "  'failed': 0,\n",
       "  'errors': []},\n",
       " 'errors': [],\n",
       " 'uploaded': {'total': {'items': 0, 'size': 0, 'human_size': '0 b'},\n",
       "  'images': {'items': 0, 'size': 0, 'human_size': '0 b'},\n",
       "  'annotations': {'items': 0, 'size': 0, 'human_size': '0 b'},\n",
       "  'archives': {'items': 0, 'size': 0, 'human_size': '0 b'}}}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_dataset.add_data(local_files=annotation_files, annotation_task = 'Object detection')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now see annotation statistics and visually explore the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'AnnotationSet ID': 44,\n",
       "  'AnnotationSet name': 'Object detection',\n",
       "  'n_images': 9,\n",
       "  'n_classes': 15,\n",
       "  'n_objects': 84,\n",
       "  'top_3_classes': [{'name': 'Fruit', 'count': 27},\n",
       "   {'name': 'Sports equipment', 'count': 12},\n",
       "   {'name': 'Human arm', 'count': 7}],\n",
       "  'creation_date': None,\n",
       "  'last_modified_date': '2020-05-29T13:56:05.883892Z'}]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_dataset.get_annotation_statistics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_dataset.view()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![dataset_added_annotation.jpeg](assets/dataset_added_annotation.jpeg) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add predictions or custom annotations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**To add data programatically from any format, we can use the `Annotation` object**\n",
    "\n",
    "\n",
    "This can be useful to:\n",
    "\n",
    "- upload model predictions\n",
    "- upload annotations from any custom file format\n",
    "- create an active learning workflow\n",
    "\n",
    "**Example: let's add annotations to a specific image using `add_annotations()` method of the dataset class**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress 100% - 1/1 - elapsed 0:00:00.001000 - speed: 1000.00 img / s, ETA: 0:00:00\n",
      "Acquiring data - completed                                                                           \n",
      "Processing data - completed                                                                          \n",
      "Data upload completed\n"
     ]
    }
   ],
   "source": [
    "image_name = '000a1249af2bc5f0.jpg'\n",
    "\n",
    "annotations = []\n",
    "\n",
    "annotation = remo.Annotation()\n",
    "annotation.img_filename = image_name\n",
    "annotation.classes='Human hand'\n",
    "annotation.bbox=[227, 284, 678, 674]\n",
    "annotations.append(annotation)\n",
    "\n",
    "annotation = remo.Annotation()\n",
    "annotation.img_filename = image_name\n",
    "annotation.classes='Fashion accessory'\n",
    "annotation.bbox=[496, 322, 544,370]\n",
    "annotations.append(annotation)\n",
    "\n",
    "my_dataset.add_annotations(annotations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now retrieve the picture and visualise it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_image = my_dataset.image(image_name)\n",
    "my_image.view()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![dataset_added_annotation.jpeg](assets/added_annotation.jpeg) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Annotation sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Under the hood, Remo organises annotations in an annotation set, which is just a version of all the annotations of a dataset.**\n",
    "\n",
    "There are 2 great advantages of using annotation sets:\n",
    "\n",
    "1. high-level operations on all the annotations with just one command\n",
    "2. easily manage multiple versions of annotations\n",
    "\n",
    "<div class=\"alert alert-info\"><b> What you can do with annotation sets</b><p>\n",
    "When training a model, it's not always clear what's the right way to label data. \n",
    "Using annotation sets, this exploration becomes easier as you can for example:\n",
    "\n",
    "- see stats of your data\n",
    "- change labels for objects from one class to another\n",
    "- delete objects of specific classes\n",
    "- compare different annotation sets (such as ground truth vs prediction, or annotations coming from different annotators)\n",
    "   \n",
    "    \n",
    "In the example we have seen above, Remo automatically creates an annotation set. For more control, it's possible to explicit manipulate Annotation sets objects thesmelves.\n",
    "\n",
    "To read more about annotation sets, you can check the remo documentation: [https://remo.ai/docs/](https://remo.ai/docs/annotation-formats/).\n",
    "    \n",
    "</p></div>\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "307.2px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
