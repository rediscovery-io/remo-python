{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Uploading Annotations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this tutorial, we explore some different options to upload annotations in Remo. We will:\n",
    "\n",
    "- add annotations from a file in a format supported by remo\n",
    "- add annotations from code, which enables uploading annotations from any input format\n",
    "- introduce the concept of Annotation Sets, for finer control over annotations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start off by creating a dataset and populating it with some images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Launching Remo server ...\n",
      "Wait a bit...  5\n",
      "\n",
      "    (\\(\\ \n",
      "    (>':') Remo server is running: {'app': 'remo', 'version': '0.3.10-53-g3012aa79'}\n",
      "                    \n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import remo\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "urls = ['https://remo-scripts.s3-eu-west-1.amazonaws.com/open_images_sample_dataset.zip']\n",
    "my_dataset = remo.create_dataset(name = 'D1', urls = urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ImageID', 'Source', 'LabelName', 'Confidence', 'XMin', 'XMax', 'YMin',\n",
       "       'YMax', 'IsOccluded', 'IsTruncated', 'IsGroupOf', 'IsDepiction',\n",
       "       'IsInside'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "annotation_files=[os.getcwd() + '/assets/open_sample.csv']\n",
    "\n",
    "df = pd.read_csv(annotation_files[0])\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Annotation set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Annotation sets represent a collection of annotations for all the images within a Dataset.\n",
    "An annotation set is characterized by a task (such as 'Object Detection') and a list of classes.\n",
    "\n",
    "The advantage of grouping annotations in an Annotation Set is that it allows for high-level group operations on all the annotations, such:\n",
    "- grouping classes together\n",
    "- deleting objects of specific classes\n",
    "- comparing of different annotations (such as ground truth vs prediction, or annotations coming from different annotators)\n",
    "\n",
    "\n",
    "**Let's first create an empty annotation set with a predetermined list of classes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_classes = ['Airplane', 'Clothing', 'Dog', 'Fashion accessory', 'Food', 'Footwear', 'Fruit', 'Human arm', \n",
    "         'Human body', 'Human hand', 'Human leg', 'Mammal', 'Man', 'Person', 'Salad', 'Sports equipment', 'Trousers', 'Woman']\n",
    "\n",
    "annotation_set = my_dataset.create_annotation_set(annotation_task = 'Object detection',\n",
    "                                          name = 'Objects',\n",
    "                                          classes = my_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can easily retrieve different annotation sets of a dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Annotation set 17 - 'Objects', task: Object detection, #classes: 18]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_dataset.annotation_sets()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add annotations from supported file format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If your annotations are already in a format supported by Remo, you can upload them right away using\n",
    "my_dataset.add_data().\n",
    "\n",
    "**As an example, let's see how to add some annotations from a CSV file**\n",
    "\n",
    "In thiss case, annotations are stored in a CSV file in a format already supported by Remo. Class labels were encoded using [GoogleKnowledgeGraph](https://developers.google.com/knowledge-graph)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When adding the file to the annotation set, remo automatically: \n",
    "- detects the class encoding and translates it into the corresponding labels\n",
    "- only adds annotations for classes that are part of the existing annotation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'files_link_result': {'files uploaded': 0, 'annotations': 9, 'errors': []}}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_dataset.add_data(local_files=annotation_files, annotation_task = 'Object detection')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'AnnotationSet ID': 17,\n",
       "  'AnnotationSet name': 'Objects',\n",
       "  'n_images': 9,\n",
       "  'n_classes': 18,\n",
       "  'n_objects': 84,\n",
       "  'top_3_classes': [{'name': 'Fruit', 'count': 27},\n",
       "   {'name': 'Sports equipment', 'count': 12},\n",
       "   {'name': 'Mammal', 'count': 7}],\n",
       "  'creation_date': None,\n",
       "  'last_modified_date': '2020-03-08T16:35:05.643905Z'}]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_dataset.get_annotation_statistics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Open http://localhost:8123/datasets/26\n"
     ]
    }
   ],
   "source": [
    "my_dataset.view()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![dataset_added_annotation.jpeg](assets/dataset_added_annotation.jpeg) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add annotations from custom formats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In case your annotations are in a custom format, as long as the task is one of those currently supported by Remo, it's still very easy to upload annotations from code.\n",
    "\n",
    "**As an example, let's see how we can add annotations to a specific image from code**\n",
    "\n",
    "This can be useful for instance to add model predictions as annotations or to tag specific images.\n",
    "\n",
    "First, let's retrieve one image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image: 936 - 000a1249af2bc5f0.jpg\n",
      "Resoultion:  1024 x 678\n"
     ]
    }
   ],
   "source": [
    "images = my_dataset.images()\n",
    "my_image = images[1]\n",
    "print(my_image)\n",
    "print('Resoultion: ', my_image.width, 'x', my_image.height)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Now we can easily add annotations using add_annotations() method of the dataset class**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotations = []\n",
    "\n",
    "annotation = remo.Annotation()\n",
    "annotation.img_filename = my_image.name\n",
    "annotation.classes='Human hand'\n",
    "annotation.bbox=[227, 284, 678, 674]\n",
    "annotations.append(annotations)\n",
    "\n",
    "annotation = remo.Annotation()\n",
    "annotation.img_filename = my_image.name\n",
    "annotation.classes='Human hand'\n",
    "annotation.bbox=[311, 193, 607, 526]\n",
    "annotations.append(annotations)\n",
    "\n",
    "annotation = remo.Annotation()\n",
    "annotation.img_filename = my_image.name\n",
    "annotation.classes='Fashion accessory'\n",
    "annotation.bbox=[496, 322, 544,370]\n",
    "annotations.append(annotations)\n",
    "\n",
    "ds.add_annotations(annotations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In case your input data is in a custom file, you can write a parser to load annotations using the Annotation object."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
